{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsaha205/Fall_22_PML/blob/main/PML_HW_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1\n",
        "\n"
      ],
      "metadata": {
        "id": "nMGT3_tN0gge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Framework:** Pytorch\n",
        "\n",
        "**Dataset:** FashionMNIST from torchvision.datasets (https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html).\n",
        "\n",
        "**Resources:**\n",
        "1. Optimizer: I used Adam optimizer from torch.optim (https://pytorch.org/docs/stable/optim.html).\n",
        "2. MLP: Used torch.nn for implementing 2-layer NN model (https://pytorch.org/docs/stable/nn.html).\n",
        "3. Plot: For plotting the data, I used matplotlib.pyplot library (https://matplotlib.org/3.5.1/api/_as_gen/matplotlib.pyplot.html).\n",
        "4. Loss function: For loss function, I used cross_entropy loss from F.cross_entropy (https://pytorch.org/docs/stable/nn.functional.html).\n",
        "5. Class Identify: To identify right class, I used log_softmax from F.log_softmax (https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html)."
      ],
      "metadata": {
        "id": "oybGznHCVvmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "m9L1n4M7YIZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "onHdRTJuYOOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as du\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "hueqaq_JN2hy"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read FashionMNIST data from torchvision.datasets\n",
        "train_data = datasets.FashionMNIST('.', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "test_data = datasets.FashionMNIST('.', train=False, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "# print(\"train_data:\", torch.take(train_data, [0,1]))\n",
        "# In the first step we will split train data in training and validation dataset. As we have seperate test dataset we don't need that.\n",
        "# train_data, valid_data, train_target, valid_target = train_test_split(train_data.data, train_data.targets, test_size=0.15, random_state=42)\n",
        "# train_data, valid_data = train_test_split(train_data.data, test_size=0.15, random_state=42)\n",
        "\n",
        "# train_data = {}\n",
        "# train_data['data'] = tr_data\n",
        "# train_data['targets'] = tr_target\n",
        "\n",
        "# print the shape of the dataset\n",
        "print(\"train images:\", train_data.data.size())\n",
        "# print(\"valid_data images:\", valid_data.size())\n",
        "print(\"test images:\", test_data.data.size())"
      ],
      "metadata": {
        "id": "g3wzIkpTN6Pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75af68c-9f71-44e9-f283-d35d8872fd23"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train images: torch.Size([60000, 28, 28])\n",
            "test images: torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x5aWAO4XdCtN"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the very first image of train dataset with label\n",
        "plt.imshow(train_data.data[0].numpy(), cmap='gray')\n",
        "plt.title('%i' % train_data.targets[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "SZ_DIfcpPfk2",
        "outputId": "4cdf1c96-38e6-4a2a-be25-3b7dd7ec4ef4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the very first image of test dataset with label\n",
        "plt.imshow(test_data.data[0].numpy(), cmap='gray')\n",
        "plt.title('%i' % test_data.targets[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "mmr4TV2mPr1J",
        "outputId": "328fd988-7d15-44bf-e990-ee51b4799af1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "KWWHQE6KZFaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        '''in_dim: input layer dim\n",
        "           hidden_dim: hidden layer dim\n",
        "           out_dim: output layer dim'''\n",
        "        \n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        # images are 28x28 so we need to flatten them into 784d vector\n",
        "        self.flatten = nn.Flatten()\n",
        "        \n",
        "        #two fully connected layers\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is 28x28, flatten it first\n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        # compute output of fc1, and then apply relu activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        \n",
        "        # compute output layer\n",
        "        # no activation: cross entropy will compute softmax\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "AbLxIfW8QFPo"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "3GdV0vH6O3w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = f'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "#hyper-paramets defining\n",
        "batch_size = 1000\n",
        "learning_rate = 0.01\n",
        "epochs = 5\n",
        "in_dim = 28 # images are 28x28 as inputs\n",
        "hidden_dim = 256 # 384d hidden layer\n",
        "number_of_class = 10 # output is 10d since there are 10 classes\n",
        "\n",
        "# set model\n",
        "model = MLP(in_dim*in_dim, hidden_dim, number_of_class)\n",
        "\n",
        "# optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# load training data in batches\n",
        "train_loader = du.DataLoader(dataset=train_data,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=True)\n",
        "# send model over to device\n",
        "model = model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_ELw38ZY_6f",
        "outputId": "b54738e2-8b9f-4356-fdb9-06f16b53103a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop over batches"
      ],
      "metadata": {
        "id": "nTbtmbCzPCYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):    \n",
        "    sum_valid_loss = 0.\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        # send batch over to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # zero out prev gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # run the forward pass\n",
        "        output = model(data)\n",
        "        \n",
        "        # compute loss/error\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        # I used first 50000 datapoints of train_data as trainig dataset and last 10000 points as validation dataset\n",
        "        if batch_idx >= 50:\n",
        "          # sum up batch losses for validation dataset\n",
        "          sum_valid_loss += loss.item()\n",
        "          continue\n",
        "        \n",
        "        # compute gradients and take a step in training phase\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    # average loss per example    \n",
        "    sum_valid_loss /= 10000\n",
        "    print(f'Epoch: {epoch}, Validation Loss: {sum_valid_loss:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "eYeYugjpZIgx",
        "outputId": "4fcdcc29-b20f-41ff-d538-20c290e7c9dd"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Validation Loss: 0.000320\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-5a6217c82ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msum_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# send batch over to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "6MdlmpB5PQDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load test images in batches\n",
        "test_loader = du.DataLoader(dataset=test_data,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True)\n",
        "\n",
        "# set model in eval mode as we are no longer training\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# turning of gradient computation that will speed up testing\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        # send batches to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # compute forward pass and loss\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        \n",
        "        # sum up batch loss\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # get the class of the max log-probability\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        pred = output.max(dim=1)[1]\n",
        "\n",
        "        # add up number of correct predictions\n",
        "        correct += torch.sum(pred == target)\n",
        "  \n",
        "    # test loss per example\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    \n",
        "    # final test accuracy\n",
        "    test_acc = correct / len(test_loader.dataset)\n",
        "    print(f'Test loss: {test_loss:.6f}, accuracy: {test_acc:.4f}', f'correct: {correct}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b54RWuKdZS58",
        "outputId": "6a87cf44-4244-4d56-b80d-8b7738eb01af"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.000376, accuracy: 0.8646 correct: 8646\n"
          ]
        }
      ]
    }
  ]
}